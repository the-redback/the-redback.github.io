[{"authors":["admin"],"categories":null,"content":"Hey, I\u0026#39;m Maruf!  I like to tear down build stuff!! 😉 I am a passionate software engineer with 4 years of professional working experience in both  developing **Kubernetes** tools in **GO** and managing microservice based infrastructure in production.  Acted as AppsCode\u0026#39;s **KubeDB project head** for more than a year. Love to participate in  **programming contests**. An enthusiastic team player. --  Passionate software engineer with 5 years of software development experience in Go, Java, and C++. Also worked as a DevOps Engineer for a year to gain hands-on experience of the infrastructure. Acted as team lead of AppsCode’s KubeDB project. Love to participate in programming contests. An enthusiastic team player.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://the-maruf.com/author/abdullah-al-maruf/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/abdullah-al-maruf/","section":"authors","summary":"Hey, I'm Maruf!  I like to tear down build stuff!! 😉 I am a passionate software engineer with 4 years of professional working experience in both  developing **Kubernetes** tools in **GO** and managing microservice based infrastructure in production.","tags":null,"title":"Abdullah Al Maruf","type":"authors"},{"authors":["Tomas Cerny","Amr S. Abdelfattah","Abdullah Al Maruf","Andrea Janes","Davide Taibi"],"categories":[],"content":"","date":1693526400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704871802,"objectID":"5c5e28f4b006da14e59969666e9a4b6f","permalink":"https://the-maruf.com/publication/cerny-2023111829/","publishdate":"2024-01-10T07:30:02.176452Z","relpermalink":"/publication/cerny-2023111829/","section":"publication","summary":"Background: Various works investigated microservice anti-patterns and bad smells in the past few years. We identified seven secondary publications that summarize these, but they have little overlap in purpose and often use different terms to describe the identified anti-patterns and smells. Objective: This work catalogs recurring bad design practices known as anti-patterns and bad smells for microservice architectures, and provides a classification into categories as well as methods for detecting these practices. Method: We conducted a systematic literature review in the form of a tertiary study targeting secondary studies identifying poor design practices for microservices. Results: We provide a comprehensive catalog of 58 disjoint anti-patterns, grouped into five categories, which we derived from 203 originally identified anti-patterns for microservices. Conclusion: The results provide a reference to microservice developers to design better-quality systems and researchers who aim to detect system quality based on anti-patterns. It also serves as an anti-pattern catalog for development-aiding tools, which are not currently available for microservice system development but could mitigate quality degradation throughout system evolution.","tags":["Microservices","Anti-patterns","Antipatterns","Anti patterns","Bad smells","Software maintenance"],"title":"Catalog and detection techniques of microservice anti-patterns and bad smells: A tertiary study","type":"publication"},{"authors":["Garrett Parker","Samuel Kim","Abdullah Al Maruf","Tomas Cerny","Karel Frajtak","Pavel Tisnovsky","Davide Taibi"],"categories":[],"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704871802,"objectID":"a8e5b321b4c10648cb4a450a9bc19351","permalink":"https://the-maruf.com/publication/10015027/","publishdate":"2024-01-10T07:30:02.33917Z","relpermalink":"/publication/10015027/","section":"publication","summary":"In the world of microservices, companies must be able to create systems that operate in the most efficient way. To achieve this, anti-patterns must be avoided because of their detriment to the quality of the system. Some of the most troubling anti-patterns are hard to detect because of their appearance at runtime. Effectively removing anti-patterns from a system requires dynamic analysis because of the large size of microservice-based systems. While the detection of anti-patterns is helpful, being able to visualize them offers a great benefit to companies working with microservices. Seeing how the overall system is flowing and recognizing the existence of anti-patterns can help improve microservice-based systems. In this paper, a systematic mapping study was performed to find the current state of research on visualizing anti-patterns in microservices from the dynamic perspective. Several hundred papers were examined and a total of 31 were found to be relevant to the research topic. The papers, when analyzed, revealed that there are mechanisms to detect anti-patterns at runtime in microservices, and there are also mechanisms for visualizing the architecture of a microservice-based system. This study’s findings could help to identify and remove anti-patterns that occur during runtime in microservices, as well as a means of visualizing these anti-patterns.","tags":[""],"title":"Visualizing Anti-Patterns in Microservices at Runtime: A Systematic Mapping Study","type":"publication"},{"authors":["Mia E. Gortney","Patrick E. Harris","Tomas Cerny","Abdullah Al Maruf","Miroslav Bures","Davide Taibi","Pavel Tisnovsky"],"categories":[],"content":"","date":1667260800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704871802,"objectID":"a343290fedafffba4820949d9293913a","permalink":"https://the-maruf.com/publication/9944666/","publishdate":"2024-01-10T07:30:02.441705Z","relpermalink":"/publication/9944666/","section":"publication","summary":"As microservices become more popular, more drawbacks become apparent to developers. One issue that many teams face today is the failure to visualize the entire system architecture holistically. Without a full view of the system, the architecture can become convoluted as teams add and subtract from their system without reconciling their changes. One established practice to determine a view on the entire system involves dynamic analysis of microservice interaction and dependencies. In this mapping study, we investigate dynamic analysis as a way to visualize system architecture. Capturing the architectural view with dynamic analysis has the ability to build the system and then show its behavior at run-time. We identify dynamic analysis techniques, the corresponding tools, and the models that these practices can generate. The findings of this study are relevant to developers of decentralized systems looking for a way to visualize their system architecture in a dynamic perspective.","tags":[""],"title":"Visualizing Microservice Architecture in the Dynamic Perspective: A Systematic Mapping Study","type":"publication"},{"authors":["Tomas Cerny","Amr S. Abdelfattah","Vincent Bushong","Abdullah Al Maruf","Davide Taibi"],"categories":[],"content":"","date":1659312000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704871802,"objectID":"4e281c5e2aa16a11aaface05234b18a2","permalink":"https://the-maruf.com/publication/9912633/","publishdate":"2024-01-10T07:30:02.755579Z","relpermalink":"/publication/9912633/","section":"publication","summary":"Microservice system solutions are now mainstream. The older microservices-based systems are not more than 15 years old, and their architecture is by far different than the one originally designed because of several changes applied to the systems due to the implementation of new features and bug fixing. The evolution of these legacy systems is therefore subjected to degradation. One of the most important methods to identify degradation is being able to reconstruct the software architecture of a system based on the current system running in production. Different methods have been proposed in the past: methods based on the static analysis of the source code of the microservices and methods based on the analysis of the log traces collected at runtime. Both static and dynamic analysis-based methods have their pros ad cons. In this work, we review the existing technologies for static and dynamic architectural reconstruction and related tools adopted to visualize the reconstructed architecture. The result of this work can be useful both to practitioners and researchers that can further develop these methods to provide better support for architectural degradation.","tags":[""],"title":"Microservice Architecture Reconstruction and Visualization Techniques: A Review","type":"publication"},{"authors":["Tomas Cerny","Amr S. Abdelfattah","Vincent Bushong","Abdullah Al Maruf","Davide Taibi"],"categories":[],"content":"","date":1659312000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704871802,"objectID":"4da34e6f1201a0e70ce55289411f4d48","permalink":"https://the-maruf.com/publication/9912621/","publishdate":"2024-01-10T07:30:02.650062Z","relpermalink":"/publication/9912621/","section":"publication","summary":"Microservices are supporting digital transformation; however, fundamental tools and system perspectives are missing to better observe, understand, and manage these systems, their properties, and their dependencies. Microservices architecture leans toward decentralization, which yields many advantages to system operation; it, however, brings challenges to their development. Microservices lack a system-centric perspective to better cope with system evolution and quality assessment. In this work, we explore microservice-specific architecture reconstruction based on static analysis. Such reconstruction typically results in system models to visualize selected system-centric perspectives. Conventional models are limited in utility when the service cardinality is high. We consider an alternative data visualization using 3D space using augmented reality. To begin testing the feasibility of deriving such perspectives from microservice systems, we developed and implemented prototype tools for software architecture reconstruction and visualization of compared perspectives.","tags":[""],"title":"Microvision: Static analysis-based approach to visualizing microservices in augmented reality","type":"publication"},{"authors":["Abdullah Al Maruf","Alexander Bakhtin","Tomas Cerny","Davide Taibi"],"categories":[],"content":"","date":1659312000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704871802,"objectID":"adde306f898fca83c255d5eb8e3ff06e","permalink":"https://the-maruf.com/publication/9912631/","publishdate":"2024-01-10T07:30:02.545053Z","relpermalink":"/publication/9912631/","section":"publication","summary":"Microservices bring various benefits to software systems. They also bring decentralization and lose coupling across self-contained system parts. Since these systems likely evolve in a decentralized manner, they need to be monitored to identify when possibly poorly designed extensions deteriorate the overall system quality. For monolith systems, such tasks have been commonly addressed through static analysis. However, given the decentralization and possible language diversity across microservices, static analysis tools are lacking. On the other hand, there are available tools commonly used by practitioners that offer centralized logging, tracing, and metric collection for microservices. In this paper, we assess the opportunity to combine current dynamic analysis tools with anomaly detection in the form of quality metrics and anti-patterns. We develop a tool prototype that we use to assess a large microservice system benchmark demonstrating the feasibility and potential of such an approach.","tags":[""],"title":"Using Microservice Telemetry Data for System Dynamic Analysis","type":"publication"},{"authors":["Alexander Bakhtin","Abdullah Al Maruf","Tomas Cerny","Davide Taibi"],"categories":[],"content":"","date":1656633600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704871802,"objectID":"60dd291f4e6a6dffe1404d5fc8e03939","permalink":"https://the-maruf.com/publication/9860229/","publishdate":"2024-01-10T07:30:02.860471Z","relpermalink":"/publication/9860229/","section":"publication","summary":"It is well recognized that design patterns improve system development and maintenance in many aspects. While we commonly recognize these patterns in monolithic systems, many patterns emerged for cloud computing, specifically microservices. Unfortunately, while various patterns have been proposed, available quality assessment tools often do not recognize many. This article performs a grey literature review to find and catalog available tools to detect microservice API patterns (MAP). It reasons about mechanisms that can be used to detect these patterns. Furthermore, the results indicate gaps and opportunities for improvements for quality assessment tools. Finally, the reader is provided with a route map to detection techniques that can be used to mine MAPs.","tags":[""],"title":"Survey on Tools and Techniques Detecting Microservice API Patterns","type":"publication"},{"authors":["Md Rofiqul Islam","Abdullah Al Maruf","Tomas Cerny"],"categories":[],"content":"","date":1654041600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704871803,"objectID":"1541abdc1800e5a6394ed735c98c7e25","permalink":"https://the-maruf.com/publication/electronics-11121880/","publishdate":"2024-01-10T07:30:02.970973Z","relpermalink":"/publication/electronics-11121880/","section":"publication","summary":"One of the most significant impediments to the long-term maintainability of software applications is code smells. Keeping up with the best coding practices can be difficult for software developers, which might lead to performance throttling or code maintenance concerns. As a result, it is imperative that large applications be regularly monitored for performance issues and code smells, so that these issues can be corrected promptly. Resolving code smells in software systems can be done in a variety of ways, but doing so all at once would be prohibitively expensive and can be out of budget. Prioritizing these solutions are therefore critical. The majority of current research prioritizes code smells according to the type of smell they cause. This method, however, is not sufficient because of a lack of knowledge regarding the frequency of code usage and code changeability behavior. Even the most complex programs have some components that are more important than others. Maintaining the functionality of certain parts is essential since they are often used. Identifying and correcting code smells in places that are frequently utilized and subject to rapid change should take precedence over other code smells. A novel strategy is proposed for finding frequently used and change-prone areas in a codebase by combining business logic, heat map information, and commit history analysis in this study. It examines the codebase, commits, and log files of Java applications to identify business processes, heat map graphs, and severity levels of various types of code smells and their commit history. This is done in order to present a comprehensive, efficient, and resource-friendly technique for identifying and prioritizing performance throttling with also handling code maintenance concerns.","tags":[],"title":"Code Smell Prioritization with Business Process Mining and Static Code Analysis: A Case Study","type":"publication"},{"authors":["Dipta Das","Abdullah Al Maruf","Rofiqul Islam","Noah Lambaria","Samuel Kim","Amr S. Abdelfattah","Tomas Cerny","Karel Frajtak","Miroslav Bures","Pavel Tisnovsky"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704871803,"objectID":"2f94cb4086885c9d2047a3863c09955d","permalink":"https://the-maruf.com/publication/10-1145-3512753-3512755/","publishdate":"2024-01-10T07:30:03.077212Z","relpermalink":"/publication/10-1145-3512753-3512755/","section":"publication","summary":"Poor design choices, bad coding practices, or the need to produce software quickly can stand behind technical debt. Unfortunately, manually identifying and managing technical debt gets more difficult as the software matures. Recent research offers various techniques to automate the process of detecting and managing technical debt to address these challenges. This manuscript presents a mapping study of the many aspects of technical debt that have been discovered in this field of study. This includes looking at the various forms of technical debt, as well as detection methods, the financial implications, and mitigation strategies. The findings and outcomes of this study are applicable to a wide range of software development life-cycle decisions.","tags":["code debt","code smells","architectural degradation","technical debt","architectural debt","design debt"],"title":"Technical Debt Resulting from Architectural Degradation and Code Smells: A Systematic Mapping Study","type":"publication"},{"authors":["Vincent Bushong","Dipta Das","Abdullah Al Maruf","Tomas Cerny"],"categories":[],"content":"","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704871803,"objectID":"2f29ebfd4298f14dfeda6c48684e0138","permalink":"https://the-maruf.com/publication/9678749/","publishdate":"2024-01-10T07:30:03.284686Z","relpermalink":"/publication/9678749/","section":"publication","summary":"Microservice design offers many advantages for enterprise applications, including increased scalability and faster deployment times. Microservices’ independence from one another in development and deployment provides these advantages. This separation, however, results in the absence of a centralized view of the application’s functionality, and each microservice’s data model is isolated and replicated. As a result, it has the potential to deviate from the architectural design’s original intent. To address this, we offer a method for analyzing a microservice mesh and generating a communication diagram, context map, and microservice-specific limited contexts using static code analysis.","tags":[""],"title":"Using Static Analysis to Address Microservice Architecture Reconstruction","type":"publication"},{"authors":["Abdullah Al Maruf","Noah Lambaria","Amr S. Abdelfattah","Tomas Cerny"],"categories":[],"content":"","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704871803,"objectID":"c50552cd84c517b85364bc23127cc2f8","permalink":"https://the-maruf.com/publication/9678532/","publishdate":"2024-01-10T07:30:03.181147Z","relpermalink":"/publication/9678532/","section":"publication","summary":"Despite the fact that there are numerous classifications of technical debt based on various criteria, Code Debt or code smells is a category that appears in the majority of current research. One of the primary causes of code debt is the urgency to deliver software quickly, as well as bad coding practices. Among many approaches, static code analysis has received the most attention in studies to detect code-smell/code debt. However, most of them examine the same programming language, although today’s software company utilizes many development stacks with various languages and tools. This problem can be resolved by detecting code debt with Issue/Ticket cards. This paper presents a method for detecting code debt leveraging natural language processing on issue tickets. It also proposes a method for calculating the average amount of time that a code debt was present in the software. This method is implemented utilizing git mining.","tags":[""],"title":"Using Version Control and Issue Tickets to detect Code Debt and Economical Cost","type":"publication"},{"authors":["Vincent Bushong","Amr S. Abdelfattah","Abdullah A. Maruf","Dipta Das","Austin Lehman","Eric Jaroszewski","Michael Coffey","Tomas Cerny","Karel Frajtak","Pavel Tisnovsky","Miroslav Bures"],"categories":[],"content":"","date":1625097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704871803,"objectID":"ace31c70e664366a6e4dbcb384c113b3","permalink":"https://the-maruf.com/publication/app-11177856/","publishdate":"2024-01-10T07:30:03.389351Z","relpermalink":"/publication/app-11177856/","section":"publication","summary":"Microservice architecture has become the leading design for cloud-native systems. The highly decentralized approach to software development consists of relatively independent services, which provides benefits such as faster deployment cycles, better scalability, and good separation of concerns among services. With this new architecture, one can naturally expect a broad range of advancements and simplifications over legacy systems. However, microservice system design remains challenging, as it is still difficult for engineers to understand the system module boundaries. Thus, understanding and explaining the microservice systems might not be as easy as initially thought. This study aims to classify recently published approaches and techniques to analyze microservice systems. It also looks at the evolutionary perspective of such systems and their analysis. Furthermore, the identified approaches target various challenges and goals, which this study analyzed. Thus, it provides the reader with a roadmap to the discipline, tools, techniques, and open challenges for future work. It provides a guide towards choices when aiming for analyzing cloud-native systems. The results indicate five analytical approaches commonly used in the literature, possibly in combination, towards problems classified into seven categories.","tags":[],"title":"On Microservice Analysis and Architecture Evolution: A Systematic Mapping Study","type":"publication"},{"authors":[],"categories":["Kubernetes","kubectl","Minikube"],"content":"Kubectl Cheat Sheet \u0026gt; minikube version \u0026gt; minikube start \u0026gt; kubectl version \u0026gt; kubectl get nodes  Run app in kubernetes Run app in kubernetes by kubectl\n\u0026gt; kubectl run kubernetes-bootcamp --image=docker.io/jocatalin/kubernetes-bootcamp:v1 --port=8080  also run GRPS_Sample //problematic\n\u0026gt; kubectl run kubernetes-grpc-sample --image=maruftuhin/server_grpc_sample --port=8088  See deployments\n\u0026gt; kubectl get deployments  run proxy and echo\n\u0026gt; kubectl proxy  setting up POD_NAME variable\n\u0026gt; export POD_NAME=$(kubectl get pods -o go-template --template \u0026#39;{{range .items}}{{.metadata.name}}{{\u0026#34;\\n\u0026#34;}}{{end}}\u0026#39;) \u0026gt; echo Name of the Pod: $POD_NAME \u0026gt; curl http://localhost:8001/api/v1/proxy/namespaces/default/pods/$POD_NAME  Pods \u0026gt; kubectl get pods \u0026gt; kubectl describe pods \u0026gt; kubectl logs $POD_NAME  Execute commands on container settings up env variables\n\u0026gt; kubectl exec $POD_NAME env  run a container\n\u0026gt; kubectl exec -ti $POD_NAME bash \u0026gt; exit  Services on kubernetes \u0026gt; kubectl get services  create and expose new service\n\u0026gt; kubectl expose deployment/kubernetes-bootcamp --type=\u0026#34;NodePort\u0026#34; --port 8080  setting up Node Port variable\n\u0026gt; export NODE_PORT=$(kubectl get services/kubernetes-bootcamp -o go-template=\u0026#39;{{(index .spec.ports 0).nodePort}}\u0026#39;) \u0026gt; echo NODE_PORT=$NODE_PORT  accessing POD from external\n\u0026gt; curl host01:$NODE_PORT  accessing pod from internal\n\u0026gt; kubectl exec -ti $POD_NAME curl localhost:8080  get description of only one deployment\n\u0026gt; kubectl get pods -l \u0026lt;label\u0026gt; i.e. \u0026gt; kubectl get pods -l run=kubernetes-bootcamp \u0026gt; kubectl get services -l run=kubernetes-bootcamp   setting up lable. 1st get POD NAME. then  \u0026gt; export POD_NAME=$(kubectl get pods -o go-template --template \u0026#39;{{range .items}}{{.metadata.name}}{{\u0026#34;\\n\u0026#34;}}{{end}}\u0026#39;) \u0026gt; echo Name of the Pod: $POD_NAME  label it  \u0026gt; kubectl label pod $POD_NAME app=v1  List of pods using label “app=v1”\n\u0026gt; kubectl get pods -l app=v1  delete services with label run=kubernetes-bootcamp\n\u0026gt; kubectl delete service -l run=kubernetes-bootcamp  Scaling \u0026gt; kubectl get deployments  scale to 4 replicas. [kubernetes–bootmcamp] is name of deloyments\n\u0026gt; kubectl scale deployments/kubernetes-bootcamp --replicas=4  current pods\n\u0026gt; kubectl get pods -o wide  Change log\n\u0026gt; kubectl describe deployments/kubernetes-bootcamp  find exposed ip and service\n\u0026gt; kubectl describe services/kubernetes-bootcamp  set environment variable NODE PORT\n\u0026gt; export NODE_PORT=$(kubectl get services/kubernetes-bootcamp -o go-template=\u0026#39;{{(index .spec.ports 0).nodePort}}\u0026#39;) \u0026gt; echo NODE_PORT=$NODE_PORT  Run this command to see which pod is serving\n\u0026gt; curl host01:$NODE_PORT  Scale down service to 2 replicas from 4 replicas\n\u0026gt; kubectl scale deployments/kubernetes-bootcamp --replicas=2  Description again\n\u0026gt; kubectl get deployments \u0026gt; kubectl get pods -o wide  Updating Application \u0026gt; kubectl get deployments \u0026gt; kubectl get pods  current image version of app\n\u0026gt; kubectl describe pods  update the image to version 2\n\u0026gt; kubectl set image deployments/kubernetes-bootcamp kubernetes-bootcamp=jocatalin/kubernetes-bootcamp:v2  Changes in Pods\n\u0026gt; kubectl get pods  Verify update service description\n\u0026gt; kubectl describe services/kubernetes-bootcamp  setting up NODE PORT\n\u0026gt; export NODE_PORT=$(kubectl get services/kubernetes-bootcamp -o go-template=\u0026#39;{{(index .spec.ports 0).nodePort}}\u0026#39;) \u0026gt; echo NODE_PORT=$NODE_PORT  rollout status command to see update\n\u0026gt; kubectl rollout status deployments/kubernetes-bootcamp  Rollback update First deploy update tag v10 for example\n\u0026gt; kubectl set image deployments/kubernetes-bootcamp kubernetes-bootcamp=jocatalin/kubernetes-bootcamp:v10  status\n\u0026gt; kubectl get deployments \u0026gt; kubectl get pods \u0026gt; kubectl describe pods # we can see, not all are v10 applied  rollback to previous working state\n\u0026gt; kubectl rollout undo deployments/kubernetes-bootcamp  Run own program docker-gRPC \u0026gt; docker images \u0026gt; kubectl run grpc-sample3 --image=maruftuhin/server_grpc_sample:tag --port=8088 \u0026gt; kubectl get pods  access from internal\n\u0026gt; kubectl proxy \u0026gt; curl --data \u0026#34;{\\\u0026#34;name\\\u0026#34;: \\\u0026#34;pc1\\\u0026#34;, \\\u0026#34;a\\\u0026#34;:2,\\\u0026#34;b\\\u0026#34;:3}\u0026#34; http://localhost:8001/api/v1/proxy/namespaces/default/pods/\u0026lt;pods id \u0026gt;/echo  access from external [Expose ]\n\u0026gt; kubectl expose deployment/grpc-sample3 --type=\u0026#34;NodePort\u0026#34; --port 8088 \u0026gt; kubectl get services/grpc-sample3  setting $Node_Port variable. but the ports can also be used from “kubectl get services/grpc-sample3” results\n\u0026gt; export NODE_PORT=$(kubectl get services/grpc-sample3 -o go-template=\u0026#39;{{(index .spec.ports 0).nodePort}}\u0026#39;) \u0026gt; kubectl get services/grpc-sample3 \u0026gt; kubectl get nodes \u0026gt; kubectl get svc grpc-sample3 -o yaml \u0026gt; minikube service grpc-sample3 --url \u0026gt; curl --data \u0026#34;{\\\u0026#34;name\\\u0026#34;: \\\u0026#34;pc1\\\u0026#34;, \\\u0026#34;a\\\u0026#34;:2,\\\u0026#34;b\\\u0026#34;:3}\u0026#34; http://192.168.99.100:32258/echo  ","date":1551550510,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551550510,"objectID":"e4bd07e84a85576bda394202fe5b95da","permalink":"https://the-maruf.com/blog/my-kubectl-cheat-sheet/","publishdate":"2019-03-03T00:15:10+06:00","relpermalink":"/blog/my-kubectl-cheat-sheet/","section":"post","summary":"Essential `kubectl` commands","tags":["Kubernetes","kubectl","Container","Minikube"],"title":"My Kubectl Cheat Sheet","type":"post"},{"authors":[],"categories":["Docker","Kubernetes","Bash"],"content":"Docker Cheat Sheet Build and run a docker image Build docker images from docker file, goto dockerfile directory and command:\ndocker build -t friendlynginx .  Run docker image from locally built image\ndocker run -d -p 50053:8088 friendlynginx # -d for running it in background //50053:8088 is the exposed port  Connect with docker hub and push to directory, a directory maruftuhin/nginx is created i docker hub at first, then login\ndocker login docker tag friendlynginx maruftuhin/nginx:tag docker push maruftuhin/nginx  Pull image from docker hub:\ndocker pull maruftuhin/nginx:tag  Run image using tag , [if locally unavailable, it pulls from online]\ndocker run -p -d 4000:8088 maruftuhin/nginx:tag  List of images and containers List of images\ndocker images  List all exited containers\ndocker ps -a -q -f status=exited  List of containers\ndocker ps -a # -a for all  Stop/remove a container or image Stop a container\ndocker stop \u0026lt;container_id\u0026gt;  Start a exited container\ndocker start \u0026lt;container id\u0026gt;  Remove an image\ndocker rmi \u0026lt;image_id\u0026gt;  Remove a container\ndocker rm \u0026lt;container id\u0026gt; docker rm \u0026lt;container_name\u0026gt;  Remove more than one image/container\ndocker rm \u0026lt;container id\u0026gt; \u0026lt;container_id\u0026gt;  Making change in a container/image Creates a container for a image and enters it directory\ndocker run -it \u0026lt;image_id\u0026gt; /bin/bash  Insert in a existing container [the container must be UP]\ndocker exec -it \u0026lt;container_id\u0026gt; bash # example: docker exec -it ecf1310ac3ed bash  Anything can be installed in that container, example, at first insert into a container and command:\napt-get update apt-get install fish apt-get install php #installs latest php  Exit container directory\nexit  Creates a image/snapshot of a [may be modified] container\ndocker commit \u0026lt;container_id\u0026gt; new_id_of_image  Executing container commands Start a exited container\ndocker start \u0026lt;container id\u0026gt;  Restart a crashed container\ndocker restart \u0026lt;contaienr_id\u0026gt;  Start fish in interactive mode\ndocker exec -it \u0026lt;container_id\u0026gt; fish  Start php inside container\ndocker exec -it \u0026lt;container_id\u0026gt; php -a echo \u0026#34;hello world\u0026#34;; exit  Names of conatiners or Images Rename existing container\ndocker rename \u0026lt;old_name\u0026gt; new_name  Giving the container a name, while rnning it\ndocker run -it --name newName \u0026lt;container_id\u0026gt; bash  Copy files from a container Create a text file inside container. insert the container and command:\ntouch test.txt  Copy from container. Exit from container and command:\ndocker cp containerName:/test.txt . #copies test.txt to host root  Copy into container\ndocker cp ./test1.txt containerName:/  Container hostnames Gives a new hostname to the container. it doesn’t change the Names of container. but when user is inside the container, it sees the hostname, in this case, it’s root@test.\ndocker run -it -h test.local \u0026lt;image_id\u0026gt; bash  Handling volumes It links between a directory of host and directory of container. in command, left side of “:” defines the source of host direcotry and right side defines destination into container.In this case, changing in ~/data of directory of host machine also takes place changing in container automatically\nBind mounts, the pasth is absolute here\ndocker run -it --name test21 -v ~/data:/data \u0026lt;image_id\u0026gt; bash  Volume help\ndocker volume --help  Inspect a docker container\ndocker inspect \u0026lt;container_id\u0026gt;  Named volume [non-bind mount], here the path is not absolute\ndocker run -it -v data:/data \u0026lt;container_id\u0026gt; bash  Used volumes of local machine in container\ndocker volume ls  If same volume is used in another container, they will share the volume.\ndocker run -it -v data:/data \u0026lt;container_id\u0026gt; bash //shares previous data volume  Remove docker volume, volume_name is available in docker volume ls\ndocker volume rm \u0026lt;volume_name\u0026gt;  Multiple volume\ndocker run -it -v data:/data -v myBin:/myBin \u0026lt;container_id\u0026gt; bash  Copy volume from another container\ndocker run -it --name slave --volume-from \u0026lt;master_container_id/Name\u0026gt; \u0026lt;image_id\u0026gt; bash  Inspect docker volume\ndocker volume inspect \u0026lt;volume_name\u0026gt;  Show danglisg volumes [not used by any container]\ndocker volume ls -f dangling=true  Remove one volume that is not used\ndocker volume rm \u0026lt;volume name\u0026gt;  Removing all unsed volumes\ndocker volume prune  Anonymous volume. –rm will delete anonymous volume after remove container. here /foo is a anonymous volume\ndocker run --rm -v /foo -v awesome:/bar busybox top  Untagged Images Show untagged images\ndocker images -f \u0026#34;dangling=true\u0026#34; -q  Delete all untagged images\ndocker images -f \u0026#34;dangling=true\u0026#34; -q | xargs docker rmi  Delete multiple images Delete images of same name\ndocker images --format \u0026#39;{{.Repository}}:{{.Tag}}\u0026#39; | grep \u0026#39;imagename\u0026#39; | xargs docker rmi # or, docker images -q imagename | uniq | xargs docker rmi --force  Docker killer!!! :P Stop all container\ndocker ps -a -q | xargs docker stop  Delete all container\ndocker ps -a -q | xargs docker rm  Removing all unused volumes\ndocker volume prune  Remove untagged dockers\ndocker images -q -f \u0026#34;dangling=true\u0026#34; | xargs docker rmi  Remove stopped containers\ndocker …","date":1551391530,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551391530,"objectID":"c70cad698aad80d5b89321560e23c4d6","permalink":"https://the-maruf.com/blog/my-docker-cheat-sheet/","publishdate":"2019-03-01T04:05:30+06:00","relpermalink":"/blog/my-docker-cheat-sheet/","section":"post","summary":"Essential `docker` commands.","tags":["Docker","Kubernetes","Bash"],"title":"My Docker Cheat Sheet","type":"post"},{"authors":[],"categories":["Kubernetes","MongoDB","minikube"],"content":"Replica-Sets Run MongoDB Replica Set on Kubernetes using Statefulset and PersistentVolumeClaim. Minikube kubernetes cluster is used for this post.\nCreate Secret for Key file MongoDB will use this key to communicate internal cluster.\n$ openssl rand -base64 741 \u0026gt; ./replica-sets/key.txt $ kubectl create secret generic shared-bootstrap-data --from-file=internal-auth-mongodb-keyfile=./replica-sets/key.txt secret \u0026#34;shared-bootstrap-data\u0026#34; created  Deploy MongoDB Replica-Sets YAML apiVersion: v1 kind: Service metadata: name: mongodb-service labels: name: mongo spec: ports: - port: 27017 targetPort: 27017 clusterIP: None selector: role: mongo --- apiVersion: apps/v1 kind: StatefulSet metadata: name: mongod spec: serviceName: mongodb-service replicas: 3 selector: matchLabels: role: mongo environment: test replicaset: MainRepSet template: metadata: labels: role: mongo environment: test replicaset: MainRepSet spec: containers: - name: mongod-container image: mongo:3.4 command: - \u0026#34;numactl\u0026#34; - \u0026#34;--interleave=all\u0026#34; - \u0026#34;mongod\u0026#34; - \u0026#34;--bind_ip\u0026#34; - \u0026#34;0.0.0.0\u0026#34; - \u0026#34;--replSet\u0026#34; - \u0026#34;MainRepSet\u0026#34; - \u0026#34;--auth\u0026#34; - \u0026#34;--clusterAuthMode\u0026#34; - \u0026#34;keyFile\u0026#34; - \u0026#34;--keyFile\u0026#34; - \u0026#34;/etc/secrets-volume/internal-auth-mongodb-keyfile\u0026#34; - \u0026#34;--setParameter\u0026#34; - \u0026#34;authenticationMechanisms=SCRAM-SHA-1\u0026#34; resources: requests: cpu: 0.2 memory: 200Mi ports: - containerPort: 27017 volumeMounts: - name: secrets-volume readOnly: true mountPath: /etc/secrets-volume - name: mongodb-persistent-storage-claim mountPath: /data/db volumes: - name: secrets-volume secret: secretName: shared-bootstrap-data defaultMode: 256 volumeClaimTemplates: - metadata: name: mongodb-persistent-storage-claim annotations: volume.beta.kubernetes.io/storage-class: \u0026#34;standard\u0026#34; spec: accessModes: [ \u0026#34;ReadWriteOnce\u0026#34; ] resources: requests: storage: 1Gi  Now Deploy the Yaml\n$ kc create -f ./replica-sets/mongodb-rc.yaml service \u0026#34;mongodb-service\u0026#34; created statefulset \u0026#34;mongod\u0026#34; created  Wait for Pod running and PVC $ kubectl get all NAME DESIRED CURRENT AGE statefulsets/mongod 3 3 2m NAME READY STATUS RESTARTS AGE po/mongod-0 1/1 Running 0 2m po/mongod-1 1/1 Running 0 2m po/mongod-2 1/1 Running 0 2m $ kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE mongodb-persistent-storage-claim-mongod-0 Bound pvc-ba24dc66-319a-11e8-8dd9-080027779e8d 1Gi RWO standard 1h mongodb-persistent-storage-claim-mongod-1 Bound pvc-bf2e51a5-319a-11e8-8dd9-080027779e8d 1Gi RWO standard 1h mongodb-persistent-storage-claim-mongod-2 Bound pvc-c7948f87-319a-11e8-8dd9-080027779e8d 1Gi RWO standard 1h  Setup ReplicaSet Configuration Finally, we need to connect to one of the “mongod” container processes to configure the replica set.\nRun the following command to connect to the first container. In the shell initiate the replica set (we can rely on the hostnames always being the same, due to having employed a StatefulSet):\n$ kubectl exec -it mongod-0 -c mongod-container bash $ mongo \u0026gt; rs.initiate({_id: \u0026#34;MainRepSet\u0026#34;, version: 1, members: [ { _id: 0, host : \u0026#34;mongod-0.mongodb-service.default.svc.cluster.local:27017\u0026#34; }, { _id: 1, host : \u0026#34;mongod-1.mongodb-service.default.svc.cluster.local:27017\u0026#34; }, { _id: 2, host : \u0026#34;mongod-2.mongodb-service.default.svc.cluster.local:27017\u0026#34; } ]});  Keep checking the status of the replica set, with the following command, until the replica set is fully initialised and a primary and two secondaries are present:\n\u0026gt; rs.status(); # output similar to: { \u0026#34;set\u0026#34; : \u0026#34;MainRepSet\u0026#34;, \u0026#34;date\u0026#34; : ISODate(\u0026#34;2018-03-27T12:11:31.577Z\u0026#34;), \u0026#34;myState\u0026#34; : 2, \u0026#34;term\u0026#34; : NumberLong(1), \u0026#34;syncingTo\u0026#34; : \u0026#34;mongod-2.mongodb-service.default.svc.cluster.local:27017\u0026#34;, \u0026#34;heartbeatIntervalMillis\u0026#34; : NumberLong(2000), \u0026#34;optimes\u0026#34; : { \u0026#34;lastCommittedOpTime\u0026#34; : { \u0026#34;ts\u0026#34; : Timestamp(1522152676, 1), \u0026#34;t\u0026#34; : NumberLong(1) }, \u0026#34;appliedOpTime\u0026#34; : { \u0026#34;ts\u0026#34; : Timestamp(1522152686, 1), \u0026#34;t\u0026#34; : NumberLong(1) }, \u0026#34;durableOpTime\u0026#34; : { \u0026#34;ts\u0026#34; : Timestamp(1522152686, 1), \u0026#34;t\u0026#34; : NumberLong(1) } }, \u0026#34;members\u0026#34; : [ { \u0026#34;_id\u0026#34; : 0, \u0026#34;name\u0026#34; : \u0026#34;mongod-0.mongodb-service.default.svc.cluster.local:27017\u0026#34;, \u0026#34;health\u0026#34; : 1, \u0026#34;state\u0026#34; : 1, \u0026#34;stateStr\u0026#34; : \u0026#34;PRIMARY\u0026#34;, \u0026#34;uptime\u0026#34; : 399, \u0026#34;optime\u0026#34; : { \u0026#34;ts\u0026#34; : Timestamp(1522152686, 1), \u0026#34;t\u0026#34; : NumberLong(1) }, \u0026#34;optimeDurable\u0026#34; : { \u0026#34;ts\u0026#34; : Timestamp(1522152686, 1), \u0026#34;t\u0026#34; : NumberLong(1) }, \u0026#34;optimeDate\u0026#34; : ISODate(\u0026#34;2018-03-27T12:11:26Z\u0026#34;), \u0026#34;optimeDurableDate\u0026#34; : ISODate(\u0026#34;2018-03-27T12:11:26Z\u0026#34;), \u0026#34;lastHeartbeat\u0026#34; : ISODate(\u0026#34;2018-03-27T12:11:30.360Z\u0026#34;), \u0026#34;lastHeartbeatRecv\u0026#34; : ISODate(\u0026#34;2018-03-27T12:11:30.697Z\u0026#34;), \u0026#34;pingMs\u0026#34; : NumberLong(0), \u0026#34;electionTime\u0026#34; : Timestamp(1522152306, 1), \u0026#34;electionDate\u0026#34; : ISODate(\u0026#34;2018-03-27T12:05:06Z\u0026#34;), \u0026#34;configVersion\u0026#34; : 1 }, { \u0026#34;_id\u0026#34; : 1, \u0026#34;name\u0026#34; : \u0026#34;mongod-1.mongodb-service.default.svc.cluster.local:27017\u0026#34;, \u0026#34;health\u0026#34; : 1, \u0026#34;state\u0026#34; : 2, \u0026#34;stateStr\u0026#34; : \u0026#34;SECONDARY\u0026#34;, \u0026#34;uptime\u0026#34; : 505, \u0026#34;optime\u0026#34; : { \u0026#34;ts\u0026#34; : Timestamp(1522152686, 1), \u0026#34;t\u0026#34; : NumberLong(1) }, \u0026#34;optimeDate\u0026#34; : ISODate(\u0026#34;2018-03-27T12:11:26Z\u0026#34;), \u0026#34;syncingTo\u0026#34; : \u0026#34;mongod-2.mongodb-service.default.svc.cluster.local:27017\u0026#34;, \u0026#34;configVersion\u0026#34; : 1, \u0026#34;self\u0026#34; : true }, { \u0026#34;_id\u0026#34; : 2, \u0026#34;name\u0026#34; : …","date":1547240870,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547240870,"objectID":"0acc8f44a4a00babc8f19ee0bb12bfa4","permalink":"https://the-maruf.com/blog/mongodb-replica-set-on-kubernetes/","publishdate":"2019-01-12T03:07:50+06:00","relpermalink":"/blog/mongodb-replica-set-on-kubernetes/","section":"post","summary":"Run MongoDB Replica Set on Kubernetes using *Statefulset* and *PersistentVolumeClaim*. Minikube kubernetes cluster is used for this post.","tags":["Kubernetes","MongoDB","Database","minikube","kubectl"],"title":"Mongodb Replica Set on Kubernetes","type":"post"},{"authors":null,"categories":null,"content":"A tool to automate database deploy on Kubernetes using CRD. It also takes scheduled backup of databases.\n Acted as KubeDB project head for more than a year. Conducted Bi-Weekly KubeDB Community meetings regularly. Added MongoDB, MySQL, Redis and Memcached support to KubeDB. Added MongoDB clustering system. Also, worked on PostgreSQL and Elasticsearch clustering. Worked with prometheus exporter to export database metrics.  ","date":1518296775,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1518296775,"objectID":"2891c0d7cc4ff94a3af34281cb5a677e","permalink":"https://the-maruf.com/project/kubedb/","publishdate":"2018-02-11T03:06:15+06:00","relpermalink":"/project/kubedb/","section":"project","summary":"Run production-grade databases easily on **Kubernetes**","tags":["Professional","Kubernetes","OSS"],"title":"KubeDB","type":"project"},{"authors":null,"categories":null,"content":" Worked with docker-hub APIs to collect analytic data. Stored analytical datas in Google sheets using GO client. Used pixel tracking [aka, web beacon] to event each view of GitHub or other web pages in real time.  ","date":1495832407,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1495832407,"objectID":"0cdb33103c04a01f57c434dbcf97727f","permalink":"https://the-maruf.com/project/appscode_analytics/","publishdate":"2017-05-27T03:00:07+06:00","relpermalink":"/project/appscode_analytics/","section":"project","summary":"Different esential analytics in Appscode oss tools.","tags":["Professional","Kubernetes","OSS"],"title":"Appscode/Analytics","type":"project"},{"authors":null,"categories":null,"content":" Final year thesis \u0026amp; project. Developed for both PC and Android. Tools: Unity 5 Game Engine, Android SDK, C#.  ","date":1485464787,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1485464787,"objectID":"7b74efd48ac83abd8ef4eaf6dc441414","permalink":"https://the-maruf.com/project/3d_racing_game/","publishdate":"2017-01-27T03:06:27+06:00","relpermalink":"/project/3d_racing_game/","section":"project","summary":"Final year thesis \u0026 project. Developed for both **PC** and **Android**.","tags":["Academic"],"title":"3D Racing Game","type":"project"},{"authors":null,"categories":null,"content":"","date":1466975403,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1466975403,"objectID":"5322f09d41fdfe6bda3c0d41a8e12c2f","permalink":"https://the-maruf.com/project/dsw/","publishdate":"2016-06-27T03:10:03+06:00","relpermalink":"/project/dsw/","section":"project","summary":"Academic project. Implemented using **C#** and **MySQL**.","tags":["Academic"],"title":"Department of Student Welfare (DSW) Management System","type":"project"},{"authors":null,"categories":null,"content":" Automatic Email verification project. Internship project. Tools: Java  ","date":1459026651,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1459026651,"objectID":"91ed5f9f13e9de08b95b0f76b2a7a922","permalink":"https://the-maruf.com/project/email_verification/","publishdate":"2016-03-27T03:10:51+06:00","relpermalink":"/project/email_verification/","section":"project","summary":"Internship Project. Implemented using **Java**.","tags":["Professional"],"title":"Email Verification","type":"project"},{"authors":null,"categories":null,"content":"","date":1456521063,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1456521063,"objectID":"80f057e50dd458d2e5bdde705b22216e","permalink":"https://the-maruf.com/project/data_encryption/","publishdate":"2016-02-27T03:11:03+06:00","relpermalink":"/project/data_encryption/","section":"project","summary":"Data encryption project in **Java**.","tags":["Hobby"],"title":"Data Encryption Project","type":"project"},{"authors":null,"categories":null,"content":" Academical Database Project Tools: C# and Microsoft SQL Server.  ","date":1424985014,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1424985014,"objectID":"bfd6987a36052da23d5f37ab06c16fdb","permalink":"https://the-maruf.com/project/library_system/","publishdate":"2015-02-27T03:10:14+06:00","relpermalink":"/project/library_system/","section":"project","summary":"Academic project. Implemented using **C#** and **Microsoft SQL Server**.","tags":["Academic"],"title":"Library Management System","type":"project"},{"authors":null,"categories":null,"content":"","date":1330290627,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1330290627,"objectID":"1cfe293321ef3cd90cdf44b7e435c1a3","permalink":"https://the-maruf.com/project/scientific_calculator/","publishdate":"2012-02-27T03:10:27+06:00","relpermalink":"/project/scientific_calculator/","section":"project","summary":"Academic project. Implemented using **Java swing**.","tags":["Academic"],"title":"Scientific Calculator","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"18d05a63a1c8d7ed973cc51838494e41","permalink":"https://the-maruf.com/privacy/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/privacy/","section":"","summary":"","tags":null,"title":"","type":"page"}]