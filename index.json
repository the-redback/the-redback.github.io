[{"authors":null,"categories":null,"content":" Hey, I'm Maruf!  I like to tear down build stuff!! 😉  I am a passionate software engineer with 2 years of working experience developing Kubernetes tools in GO. Acted as AppsCode\u0026rsquo;s KubeDB project head for more than a year. Love to participate in programming contests. An enthusiastic team player.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"https://maruftuhin.com/author/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/admin/","section":"author","summary":" Hey, I'm Maruf!  I like to tear down build stuff!! 😉  I am a passionate software engineer with 2 years of working experience developing Kubernetes tools in GO. Acted as AppsCode\u0026rsquo;s KubeDB project head for more than a year. Love to participate in programming contests. An enthusiastic team player.\n ","tags":null,"title":"Abdullah Al Maruf","type":"author"},{"authors":[],"categories":["kubernetes","kubectl","minikube"],"content":" Kubectl Cheat Sheet \u0026gt; minikube version \u0026gt; minikube start \u0026gt; kubectl version \u0026gt; kubectl get nodes  Run app in kubernetes example code of kubernetes\n\u0026gt; kubectl run kubernetes-bootcamp --image=docker.io/jocatalin/kubernetes-bootcamp:v1 --port=8080  also run GRPS_Sample //problematic\n\u0026gt; kubectl run kubernetes-grpc-sample --image=maruftuhin/server_grpc_sample --port=8088  See deployments\n\u0026gt; kubectl get deployments  run proxy and echo\n\u0026gt; kubectl proxy  setting up POD_NAME variable\n\u0026gt; export POD_NAME=$(kubectl get pods -o go-template --template '{{range .items}}{{.metadata.name}}{{\u0026quot;\\n\u0026quot;}}{{end}}') \u0026gt; echo Name of the Pod: $POD_NAME \u0026gt; curl http://localhost:8001/api/v1/proxy/namespaces/default/pods/$POD_NAME  Pods \u0026gt; kubectl get pods \u0026gt; kubectl describe pods \u0026gt; kubectl logs $POD_NAME  Execute commands on container settings up env variables\n\u0026gt; kubectl exec $POD_NAME env  run a conainer\n\u0026gt; kubectl exec -ti $POD_NAME bash \u0026gt; exit  Services on kubernetes \u0026gt; kubectl get services  create and expose new service\n\u0026gt; kubectl expose deployment/kubernetes-bootcamp --type=\u0026quot;NodePort\u0026quot; --port 8080  setting up Node Port variable\n\u0026gt; export NODE_PORT=$(kubectl get services/kubernetes-bootcamp -o go-template='{{(index .spec.ports 0).nodePort}}') \u0026gt; echo NODE_PORT=$NODE_PORT  accessing POD from external\n\u0026gt; curl host01:$NODE_PORT  accessing pod from internal\n\u0026gt; kubectl exec -ti $POD_NAME curl localhost:8080  get description of only one deployment\n\u0026gt; kubectl get pods -l \u0026lt;label\u0026gt; i.e. \u0026gt; kubectl get pods -l run=kubernetes-bootcamp \u0026gt; kubectl get services -l run=kubernetes-bootcamp   setting up lable. 1st get POD NAME. then  \u0026gt; export POD_NAME=$(kubectl get pods -o go-template --template '{{range .items}}{{.metadata.name}}{{\u0026quot;\\n\u0026quot;}}{{end}}') \u0026gt; echo Name of the Pod: $POD_NAME   label it  \u0026gt; kubectl label pod $POD_NAME app=v1  List of pods using label \u0026ldquo;app=v1\u0026rdquo;\n\u0026gt; kubectl get pods -l app=v1  delete services with label run=kubernetes-bootcamp\n\u0026gt; kubectl delete service -l run=kubernetes-bootcamp  Scaling \u0026gt; kubectl get deployments  scale to 4 replicas. [kubernetes\u0026ndash;bootmcamp] is name of deloyments\n\u0026gt; kubectl scale deployments/kubernetes-bootcamp --replicas=4  current pods\n\u0026gt; kubectl get pods -o wide  Change log\n\u0026gt; kubectl describe deployments/kubernetes-bootcamp  find exposed ip and service\n\u0026gt; kubectl describe services/kubernetes-bootcamp  set environment variable NODE PORT\n\u0026gt; export NODE_PORT=$(kubectl get services/kubernetes-bootcamp -o go-template='{{(index .spec.ports 0).nodePort}}') \u0026gt; echo NODE_PORT=$NODE_PORT  Run this command to see which pod is servicing\n\u0026gt; curl host01:$NODE_PORT  Scale down service to 2 replicas from 4 replicas\n\u0026gt; kubectl scale deployments/kubernetes-bootcamp --replicas=2  Description again\n\u0026gt; kubectl get deployments \u0026gt; kubectl get pods -o wide  Updating Application \u0026gt; kubectl get deployments \u0026gt; kubectl get pods  current image version of app\n\u0026gt; kubectl describe pods  update the image to version 2\n\u0026gt; kubectl set image deployments/kubernetes-bootcamp kubernetes-bootcamp=jocatalin/kubernetes-bootcamp:v2  Changes in Pods\n\u0026gt; kubectl get pods  Verify update service description\n\u0026gt; kubectl describe services/kubernetes-bootcamp  setting up NODE PORT\n\u0026gt; export NODE_PORT=$(kubectl get services/kubernetes-bootcamp -o go-template='{{(index .spec.ports 0).nodePort}}') \u0026gt; echo NODE_PORT=$NODE_PORT  rollout status command to see update\n\u0026gt; kubectl rollout status deployments/kubernetes-bootcamp  Rollback update First deploy update tag v10 for example\n\u0026gt; kubectl set image deployments/kubernetes-bootcamp kubernetes-bootcamp=jocatalin/kubernetes-bootcamp:v10  status\n\u0026gt; kubectl get deployments \u0026gt; kubectl get pods \u0026gt; kubectl describe pods # we can see, not all are v10 applied  rollback to previous working state\n\u0026gt; kubectl rollout undo deployments/kubernetes-bootcamp  Run own program docker-gRPC \u0026gt; docker images \u0026gt; kubectl run grpc-sample3 --image=maruftuhin/server_grpc_sample:tag --port=8088 \u0026gt; kubectl get pods  access from internal\n\u0026gt; kubectl proxy \u0026gt; curl --data \u0026quot;{\\\u0026quot;name\\\u0026quot;: \\\u0026quot;pc1\\\u0026quot;, \\\u0026quot;a\\\u0026quot;:2,\\\u0026quot;b\\\u0026quot;:3}\u0026quot; http://localhost:8001/api/v1/proxy/namespaces/default/pods/\u0026lt;pods id \u0026gt;/echo  access from external [Expose ]\n\u0026gt; kubectl expose deployment/grpc-sample3 --type=\u0026quot;NodePort\u0026quot; --port 8088 \u0026gt; kubectl get services/grpc-sample3  setting $Node_Port variable. but the ports can also be used from \u0026ldquo;kubectl get services/grpc-sample3\u0026rdquo; results\n\u0026gt; export NODE_PORT=$(kubectl get services/grpc-sample3 -o go-template='{{(index .spec.ports 0).nodePort}}') \u0026gt; kubectl get services/grpc-sample3 \u0026gt; kubectl get nodes \u0026gt; kubectl get svc grpc-sample3 -o yaml \u0026gt; minikube service grpc-sample3 --url \u0026gt; curl --data \u0026quot;{\\\u0026quot;name\\\u0026quot;: \\\u0026quot;pc1\\\u0026quot;, \\\u0026quot;a\\\u0026quot;:2,\\\u0026quot;b\\\u0026quot;:3}\u0026quot; http://192.168.99.100:32258/echo  ","date":1551550510,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551550510,"objectID":"7eda34558088ca3f8e79580c7b248dee","permalink":"https://maruftuhin.com/blog/kubernetes-cheatsheet/","publishdate":"2019-03-03T00:15:10+06:00","relpermalink":"/blog/kubernetes-cheatsheet/","section":"blog","summary":"Essential `kubectl` commands","tags":["kubernetes","kubectl","container","minikube"],"title":"My Kubectl Cheat Sheet","type":"post"},{"authors":[],"categories":["docker","kubernetes","bash"],"content":" Docker Cheat Sheet Build and run a docker image Build docker images from docker file, goto dockerfile directory and command:\ndocker build -t friendlynginx .  Run docker image from locally built image\ndocker run -d -p 50053:8088 friendlynginx # -d for running it in background //50053:8088 is the exposed port  Connect with docker hub and push to directory, a directory maruftuhin/nginx is created i docker hub at first, then login\ndocker login docker tag friendlynginx maruftuhin/nginx:tag docker push maruftuhin/nginx  Pull image from docker hub:\ndocker pull maruftuhin/nginx:tag  Run image using tag , [if locally unavailable, it pulls from online]\ndocker run -p -d 4000:8088 maruftuhin/nginx:tag  List of images and containers List of images\ndocker images  List all exited containers\ndocker ps -a -q -f status=exited  List of containers\ndocker ps -a # -a for all  Stop/remove a container or image Stop a container\ndocker stop \u0026lt;container_id\u0026gt;  Start a exited container\ndocker start \u0026lt;container id\u0026gt;  Remove an image\ndocker rmi \u0026lt;image_id\u0026gt;  Remove a container\ndocker rm \u0026lt;container id\u0026gt; docker rm \u0026lt;container_name\u0026gt;  Remove more than one image/container\ndocker rm \u0026lt;container id\u0026gt; \u0026lt;container_id\u0026gt;  Making change in a container/image Creates a container for a image and enters it directory\ndocker run -it \u0026lt;image_id\u0026gt; /bin/bash  Insert in a existing container [the container must be UP]\ndocker exec -it \u0026lt;container_id\u0026gt; bash # example: docker exec -it ecf1310ac3ed bash  Anything can be installed in that container, example, at first insert into a container and command:\napt-get update apt-get install fish apt-get install php #installs latest php  Exit container directory\nexit  Creates a image/snapshot of a [may be modified] container\ndocker commit \u0026lt;container_id\u0026gt; new_id_of_image  Executing container commands Start a exited container\ndocker start \u0026lt;container id\u0026gt;  Restart a crashed container\ndocker restart \u0026lt;contaienr_id\u0026gt;  Start fish in interactive mode\ndocker exec -it \u0026lt;container_id\u0026gt; fish  Start php inside container\ndocker exec -it \u0026lt;container_id\u0026gt; php -a echo \u0026quot;hello world\u0026quot;; exit  Names of conatiners or Images Rename existing container\ndocker rename \u0026lt;old_name\u0026gt; new_name  Giving the container a name, while rnning it\ndocker run -it --name newName \u0026lt;container_id\u0026gt; bash  Copy files from a container Create a text file inside container. insert the container and command:\ntouch test.txt  Copy from container. Exit from container and command:\ndocker cp containerName:/test.txt . #copies test.txt to host root  Copy into container\ndocker cp ./test1.txt containerName:/  Container hostnames Gives a new hostname to the container. it doesn\u0026rsquo;t change the Names of container. but when user is inside the container, it sees the hostname, in this case, it\u0026rsquo;s root@test.\ndocker run -it -h test.local \u0026lt;image_id\u0026gt; bash  Handling volumes It links between a directory of host and directory of container. in command, left side of \u0026ldquo;:\u0026rdquo; defines the source of host direcotry and right side defines destination into container.In this case, changing in ~/data of directory of host machine also takes place changing in container automatically\nBind mounts, the pasth is absolute here\ndocker run -it --name test21 -v ~/data:/data \u0026lt;image_id\u0026gt; bash  Volume help\ndocker volume --help  Inspect a docker container\ndocker inspect \u0026lt;container_id\u0026gt;  Named volume [non-bind mount], here the path is not absolute\ndocker run -it -v data:/data \u0026lt;container_id\u0026gt; bash  Used volumes of local machine in container\ndocker volume ls  If same volume is used in another container, they will share the volume.\ndocker run -it -v data:/data \u0026lt;container_id\u0026gt; bash //shares previous data volume  Remove docker volume, volume_name is available in docker volume ls\ndocker volume rm \u0026lt;volume_name\u0026gt;  Multiple volume\ndocker run -it -v data:/data -v myBin:/myBin \u0026lt;container_id\u0026gt; bash  Copy volume from another container\ndocker run -it --name slave --volume-from \u0026lt;master_container_id/Name\u0026gt; \u0026lt;image_id\u0026gt; bash  Inspect docker volume\ndocker volume inspect \u0026lt;volume_name\u0026gt;  Show danglisg volumes [not used by any container]\ndocker volume ls -f dangling=true  Remove one volume that is not used\ndocker volume rm \u0026lt;volume name\u0026gt;  Removing all unsed volumes\ndocker volume prune  Anonymous volume. \u0026ndash;rm will delete anonymous volume after remove container. here /foo is a anonymous volume\ndocker run --rm -v /foo -v awesome:/bar busybox top  Untagged Images Show untagged images\ndocker images -f \u0026quot;dangling=true\u0026quot; -q  Delete all untagged images\ndocker images -f \u0026quot;dangling=true\u0026quot; -q | xargs docker rmi  Delete multiple images Delete images of same name\ndocker images --format '{{.Repository}}:{{.Tag}}' | grep 'imagename' | xargs docker rmi # or, docker images -q imagename | uniq | xargs docker rmi --force  Docker killer!!! :P Stop all container\ndocker ps -a -q | xargs docker stop  Delete all container\ndocker ps -a -q | xargs docker rm  Removing all unused volumes\ndocker volume prune  Remove untagged dockers\ndocker images -q -f \u0026quot;dangling=true\u0026quot; | xargs docker rmi  Remove stopped containers\ndocker ps -aq --no-trunc -f status=exited | xargs docker rm  Remove all images\ndocker images -q | xargs docker rmi  Start fresh Dangerous!!! Deletes everything!! sudo systemctl stop docker.service sudo rm -rf /var/lib/docker sudo systemctl start docker.service  Copy Local images to Minikube For bash\ndocker save \u0026lt;image-name\u0026gt; | pv | (eval $(minikube docker-env) \u0026amp;\u0026amp; docker load) # or, docker save \u0026lt;image-name\u0026gt; | (eval $(minikube docker-env) \u0026amp;\u0026amp; docker load)  ","date":1551391530,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551391530,"objectID":"2fc72147f987f7b2f745f44dcb4f9267","permalink":"https://maruftuhin.com/blog/docker-cheatsheet/","publishdate":"2019-03-01T04:05:30+06:00","relpermalink":"/blog/docker-cheatsheet/","section":"blog","summary":"Essential `docker` commands.","tags":["docker","kubernetes","bash"],"title":"My Docker Cheat Sheet","type":"post"},{"authors":null,"categories":null,"content":"","date":1551215463,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551215463,"objectID":"80f057e50dd458d2e5bdde705b22216e","permalink":"https://maruftuhin.com/project/data_encryption/","publishdate":"2019-02-27T03:11:03+06:00","relpermalink":"/project/data_encryption/","section":"project","summary":"Data encryption project in ***Java***.","tags":["Hobby"],"title":"Data Encryption Project","type":"project"},{"authors":null,"categories":null,"content":" Automatic Email verification project. Internship project. Tools: Java  ","date":1551215451,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551215451,"objectID":"91ed5f9f13e9de08b95b0f76b2a7a922","permalink":"https://maruftuhin.com/project/email_verification/","publishdate":"2019-02-27T03:10:51+06:00","relpermalink":"/project/email_verification/","section":"project","summary":"Internship Project. Implemented using ***Java***.","tags":["Professional"],"title":"Email Verification","type":"project"},{"authors":null,"categories":null,"content":"","date":1551215427,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551215427,"objectID":"1cfe293321ef3cd90cdf44b7e435c1a3","permalink":"https://maruftuhin.com/project/scientific_calculator/","publishdate":"2019-02-27T03:10:27+06:00","relpermalink":"/project/scientific_calculator/","section":"project","summary":"Academic project. Implemented using ***Java swing***.","tags":["Academic"],"title":"Scientific Calculator","type":"project"},{"authors":null,"categories":null,"content":" Academical Database Project Tools: C# and Microsoft SQL Server.  ","date":1551215414,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551215414,"objectID":"bfd6987a36052da23d5f37ab06c16fdb","permalink":"https://maruftuhin.com/project/library_system/","publishdate":"2019-02-27T03:10:14+06:00","relpermalink":"/project/library_system/","section":"project","summary":"Academic project. Implemented using ***C#*** and ***Microsoft SQL Server***.","tags":["Academic"],"title":"Library Management System","type":"project"},{"authors":null,"categories":null,"content":"","date":1551215403,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551215403,"objectID":"5322f09d41fdfe6bda3c0d41a8e12c2f","permalink":"https://maruftuhin.com/project/dsw/","publishdate":"2019-02-27T03:10:03+06:00","relpermalink":"/project/dsw/","section":"project","summary":"Academic project. Implemented using ***C#*** and ***MySQL***.","tags":["Academic"],"title":"Department of Student Welfare (DSW) Management System","type":"project"},{"authors":null,"categories":null,"content":" Final year thesis \u0026amp; project. Developed for both PC and Android. Tools: Unity 5 Game Engine, Android SDK, C#.  ","date":1551215187,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551215187,"objectID":"7b74efd48ac83abd8ef4eaf6dc441414","permalink":"https://maruftuhin.com/project/3d_racing_game/","publishdate":"2019-02-27T03:06:27+06:00","relpermalink":"/project/3d_racing_game/","section":"project","summary":"Final year thesis \u0026 project. Developed for both ***PC*** and ***Android***.","tags":["Academic"],"title":"3D Racing Game","type":"project"},{"authors":null,"categories":null,"content":" Worked with docker-hub APIs to collect analytic data. Stored analytical datas in Google sheets using GO client. Used pixel tracking [aka, web beacon] to event each view of GitHub or other web pages in real time.  ","date":1551214807,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551214807,"objectID":"0cdb33103c04a01f57c434dbcf97727f","permalink":"https://maruftuhin.com/project/appscode_analytics/","publishdate":"2019-02-27T03:00:07+06:00","relpermalink":"/project/appscode_analytics/","section":"project","summary":"Different esential analytics in Appscode oss tools.","tags":["Professional","Kubernetes","OSS"],"title":"Appscode/Analytics","type":"project"},{"authors":null,"categories":null,"content":"A tool to automate database deploy on Kubernetes using CRD. It also takes scheduled backup of databases.\n Acted as KubeDB project head for more than a year. Conducted Bi-Weekly KubeDB Community meetings regularly. Added MongoDB, MySQL, Redis and Memcached support to KubeDB. Added MongoDB clustering system. Also, worked on PostgreSQL and Elasticsearch clustering. Worked with prometheus exporter to export database metrics.  ","date":1549832775,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549832775,"objectID":"2891c0d7cc4ff94a3af34281cb5a677e","permalink":"https://maruftuhin.com/project/kubedb/","publishdate":"2019-02-11T03:06:15+06:00","relpermalink":"/project/kubedb/","section":"project","summary":"Run production-grade databases easily on ***Kubernetes***","tags":["Professional","Kubernetes","OSS"],"title":"KubeDB","type":"project"},{"authors":[],"categories":["Kubernetes","MongoDB","minikube"],"content":" Replica-Sets Create Secret for Key file MongoDB will use this key to communicate internal cluster.\n$ openssl rand -base64 741 \u0026gt; ./replica-sets/key.txt $ kubectl create secret generic shared-bootstrap-data --from-file=internal-auth-mongodb-keyfile=./replica-sets/key.txt secret \u0026quot;shared-bootstrap-data\u0026quot; created  Deploy MongoDB Replica-Sets YAML apiVersion: v1 kind: Service metadata: name: mongodb-service labels: name: mongo spec: ports: - port: 27017 targetPort: 27017 clusterIP: None selector: role: mongo --- apiVersion: apps/v1 kind: StatefulSet metadata: name: mongod spec: serviceName: mongodb-service replicas: 3 selector: matchLabels: role: mongo environment: test replicaset: MainRepSet template: metadata: labels: role: mongo environment: test replicaset: MainRepSet spec: containers: - name: mongod-container image: mongo:3.4 command: - \u0026quot;numactl\u0026quot; - \u0026quot;--interleave=all\u0026quot; - \u0026quot;mongod\u0026quot; - \u0026quot;--bind_ip\u0026quot; - \u0026quot;0.0.0.0\u0026quot; - \u0026quot;--replSet\u0026quot; - \u0026quot;MainRepSet\u0026quot; - \u0026quot;--auth\u0026quot; - \u0026quot;--clusterAuthMode\u0026quot; - \u0026quot;keyFile\u0026quot; - \u0026quot;--keyFile\u0026quot; - \u0026quot;/etc/secrets-volume/internal-auth-mongodb-keyfile\u0026quot; - \u0026quot;--setParameter\u0026quot; - \u0026quot;authenticationMechanisms=SCRAM-SHA-1\u0026quot; resources: requests: cpu: 0.2 memory: 200Mi ports: - containerPort: 27017 volumeMounts: - name: secrets-volume readOnly: true mountPath: /etc/secrets-volume - name: mongodb-persistent-storage-claim mountPath: /data/db volumes: - name: secrets-volume secret: secretName: shared-bootstrap-data defaultMode: 256 volumeClaimTemplates: - metadata: name: mongodb-persistent-storage-claim annotations: volume.beta.kubernetes.io/storage-class: \u0026quot;standard\u0026quot; spec: accessModes: [ \u0026quot;ReadWriteOnce\u0026quot; ] resources: requests: storage: 1Gi  Now Deploy the Yaml\n$ kc create -f ./replica-sets/mongodb-rc.yaml service \u0026quot;mongodb-service\u0026quot; created statefulset \u0026quot;mongod\u0026quot; created  Wait for Pod running and PVC $ kubectl get all NAME DESIRED CURRENT AGE statefulsets/mongod 3 3 2m NAME READY STATUS RESTARTS AGE po/mongod-0 1/1 Running 0 2m po/mongod-1 1/1 Running 0 2m po/mongod-2 1/1 Running 0 2m $ kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE mongodb-persistent-storage-claim-mongod-0 Bound pvc-ba24dc66-319a-11e8-8dd9-080027779e8d 1Gi RWO standard 1h mongodb-persistent-storage-claim-mongod-1 Bound pvc-bf2e51a5-319a-11e8-8dd9-080027779e8d 1Gi RWO standard 1h mongodb-persistent-storage-claim-mongod-2 Bound pvc-c7948f87-319a-11e8-8dd9-080027779e8d 1Gi RWO standard 1h  Setup ReplicaSet Configuration Finally, we need to connect to one of the “mongod” container processes to configure the replica set.\nRun the following command to connect to the first container. In the shell initiate the replica set (we can rely on the hostnames always being the same, due to having employed a StatefulSet):\n$ kubectl exec -it mongod-0 -c mongod-container bash $ mongo \u0026gt; rs.initiate({_id: \u0026quot;MainRepSet\u0026quot;, version: 1, members: [ { _id: 0, host : \u0026quot;mongod-0.mongodb-service.default.svc.cluster.local:27017\u0026quot; }, { _id: 1, host : \u0026quot;mongod-1.mongodb-service.default.svc.cluster.local:27017\u0026quot; }, { _id: 2, host : \u0026quot;mongod-2.mongodb-service.default.svc.cluster.local:27017\u0026quot; } ]});  Keep checking the status of the replica set, with the following command, until the replica set is fully initialised and a primary and two secondaries are present:\n\u0026gt; rs.status(); # output similar to: { \u0026quot;set\u0026quot; : \u0026quot;MainRepSet\u0026quot;, \u0026quot;date\u0026quot; : ISODate(\u0026quot;2018-03-27T12:11:31.577Z\u0026quot;), \u0026quot;myState\u0026quot; : 2, \u0026quot;term\u0026quot; : NumberLong(1), \u0026quot;syncingTo\u0026quot; : \u0026quot;mongod-2.mongodb-service.default.svc.cluster.local:27017\u0026quot;, \u0026quot;heartbeatIntervalMillis\u0026quot; : NumberLong(2000), \u0026quot;optimes\u0026quot; : { \u0026quot;lastCommittedOpTime\u0026quot; : { \u0026quot;ts\u0026quot; : Timestamp(1522152676, 1), \u0026quot;t\u0026quot; : NumberLong(1) }, \u0026quot;appliedOpTime\u0026quot; : { \u0026quot;ts\u0026quot; : Timestamp(1522152686, 1), \u0026quot;t\u0026quot; : NumberLong(1) }, \u0026quot;durableOpTime\u0026quot; : { \u0026quot;ts\u0026quot; : Timestamp(1522152686, 1), \u0026quot;t\u0026quot; : NumberLong(1) } }, \u0026quot;members\u0026quot; : [ { \u0026quot;_id\u0026quot; : 0, \u0026quot;name\u0026quot; : \u0026quot;mongod-0.mongodb-service.default.svc.cluster.local:27017\u0026quot;, \u0026quot;health\u0026quot; : 1, \u0026quot;state\u0026quot; : 1, \u0026quot;stateStr\u0026quot; : \u0026quot;PRIMARY\u0026quot;, \u0026quot;uptime\u0026quot; : 399, \u0026quot;optime\u0026quot; : { \u0026quot;ts\u0026quot; : Timestamp(1522152686, 1), \u0026quot;t\u0026quot; : NumberLong(1) }, \u0026quot;optimeDurable\u0026quot; : { \u0026quot;ts\u0026quot; : Timestamp(1522152686, 1), \u0026quot;t\u0026quot; : NumberLong(1) }, \u0026quot;optimeDate\u0026quot; : ISODate(\u0026quot;2018-03-27T12:11:26Z\u0026quot;), \u0026quot;optimeDurableDate\u0026quot; : ISODate(\u0026quot;2018-03-27T12:11:26Z\u0026quot;), \u0026quot;lastHeartbeat\u0026quot; : ISODate(\u0026quot;2018-03-27T12:11:30.360Z\u0026quot;), \u0026quot;lastHeartbeatRecv\u0026quot; : ISODate(\u0026quot;2018-03-27T12:11:30.697Z\u0026quot;), \u0026quot;pingMs\u0026quot; : NumberLong(0), \u0026quot;electionTime\u0026quot; : Timestamp(1522152306, 1), \u0026quot;electionDate\u0026quot; : ISODate(\u0026quot;2018-03-27T12:05:06Z\u0026quot;), \u0026quot;configVersion\u0026quot; : 1 }, { \u0026quot;_id\u0026quot; : 1, \u0026quot;name\u0026quot; : \u0026quot;mongod-1.mongodb-service.default.svc.cluster.local:27017\u0026quot;, \u0026quot;health\u0026quot; : 1, \u0026quot;state\u0026quot; : 2, \u0026quot;stateStr\u0026quot; : \u0026quot;SECONDARY\u0026quot;, \u0026quot;uptime\u0026quot; : 505, \u0026quot;optime\u0026quot; : { \u0026quot;ts\u0026quot; : Timestamp(1522152686, 1), \u0026quot;t\u0026quot; : NumberLong(1) }, \u0026quot;optimeDate\u0026quot; : ISODate(\u0026quot;2018-03-27T12:11:26Z\u0026quot;), \u0026quot;syncingTo\u0026quot; : \u0026quot;mongod-2.mongodb-service.default.svc.cluster.local:27017\u0026quot;, \u0026quot;configVersion\u0026quot; : 1, \u0026quot;self\u0026quot; : true }, { \u0026quot;_id\u0026quot; : 2, \u0026quot;name\u0026quot; : \u0026quot;mongod-2.mongodb-service.default.svc.cluster.local:27017\u0026quot;, \u0026quot;health\u0026quot; : 1, \u0026quot;state\u0026quot; : 2, \u0026quot;stateStr\u0026quot; : \u0026quot;SECONDARY\u0026quot;, \u0026quot;uptime\u0026quot; : 399, \u0026quot;optime\u0026quot; : { \u0026quot;ts\u0026quot; : Timestamp(1522152686, 1), \u0026quot;t\u0026quot; : NumberLong(1) }, \u0026quot;optimeDurable\u0026quot; : { \u0026quot;ts\u0026quot; : Timestamp(1522152686, 1), \u0026quot;t\u0026quot; : NumberLong(1) }, \u0026quot;optimeDate\u0026quot; : ISODate(\u0026quot;2018-03-27T12:11:26Z\u0026quot;), \u0026quot;optimeDurableDate\u0026quot; : ISODate(\u0026quot;2018-03-27T12:11:26Z\u0026quot;), \u0026quot;lastHeartbeat\u0026quot; : ISODate(\u0026quot;2018-03-27T12:11:30.360Z\u0026quot;), \u0026quot;lastHeartbeatRecv\u0026quot; : ISODate(\u0026quot;2018-03-27T12:11:29.915Z\u0026quot;), \u0026quot;pingMs\u0026quot; : NumberLong(0), \u0026quot;syncingTo\u0026quot; : \u0026quot;mongod-0.mongodb-service.default.svc.cluster.local:27017\u0026quot;, \u0026quot;configVersion\u0026quot; : 1 } ], \u0026quot;ok\u0026quot; : 1 }  mongodb-0 has become Primary and Others two Secondary Nodes.\nThen run the following command to configure an “admin” user (performing this action results in the “localhost exception” being automatically and permanently disabled):\n\u0026gt; db.getSiblingDB(\u0026quot;admin\u0026quot;).createUser({ user : \u0026quot;main_admin\u0026quot;, pwd : \u0026quot;abc123\u0026quot;, roles: [ { role: \u0026quot;root\u0026quot;, db: \u0026quot;admin\u0026quot; } ] });  Insert Data Insert Data into mongod-0 pod.\n\u0026gt; db.getSiblingDB('admin').auth(\u0026quot;main_admin\u0026quot;, \u0026quot;abc123\u0026quot;); \u0026gt; use test; \u0026gt; db.testcoll.insert({a:1}); \u0026gt; db.testcoll.insert({b:2}); \u0026gt; db.testcoll.find();  Verify Cluster Data exec into Secondary Pod (here, mongo-1)\n$ kubectl exec -it mongod-1 -c mongod-container bash $ mongo \u0026gt; db.getSiblingDB('admin').auth(\u0026quot;main_admin\u0026quot;, \u0026quot;abc123\u0026quot;); \u0026gt; db.getMongo().setSlaveOk() \u0026gt; use test; \u0026gt; db.testcoll.find();  Verify PVC $ kubectl delete -f ./replica-sets/mongodb-rc.yaml $ kubectl get all $ kubectl get persistentvolumes  Recreate MongoDB\n$ kubectl apply -f ./replica-sets/mongodb-rc.yaml $ kubectl get all  Verify Data:\n$ kubectl exec -it mongod-0 -c mongod-container bash $ mongo \u0026gt; db.getSiblingDB('admin').auth(\u0026quot;main_admin\u0026quot;, \u0026quot;abc123\u0026quot;); \u0026gt; use test; \u0026gt; db.testcoll.find();  As PVC was not deleted, We will still have existing Data.\nVerify Clusterization Delete mongod-0 Pod and keep cheking rs.status(), eventually another node of the remaining two will become Primary Node.\n","date":1547240870,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547240870,"objectID":"28c62f4d9645cdd6eb7606bc98f9a167","permalink":"https://maruftuhin.com/blog/mongodb-on-kubernetes/","publishdate":"2019-01-12T03:07:50+06:00","relpermalink":"/blog/mongodb-on-kubernetes/","section":"blog","summary":"Run MongoDB Replica Set on Kubernetes using *Statefulset* and *PersistentVolumeClaim*. Minikube kubernetes cluster is used for this post.","tags":["Kubernetes","MongoDB","Database","minikube","kubectl"],"title":"Mongodb Replica Set on Kubernetes","type":"post"}]